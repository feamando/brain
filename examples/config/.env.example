# PM-OS Brain Environment Variables
# Copy this file to .env and fill in your values

# =============================================================================
# SLACK INTEGRATION
# =============================================================================
# Bot token for Slack API access
# Create at: https://api.slack.com/apps
SLACK_BOT_TOKEN=xoxb-your-bot-token

# User OAuth token (for user-level actions)
SLACK_USER_TOKEN=xoxp-your-user-token

# Your Slack user ID (find in Slack profile)
SLACK_USER_ID=U0123456789

# =============================================================================
# JIRA INTEGRATION
# =============================================================================
# Atlassian instance URL
JIRA_URL=https://your-company.atlassian.net

# Your Atlassian email
JIRA_USERNAME=your.email@example.com

# API token (create at: https://id.atlassian.com/manage-profile/security/api-tokens)
JIRA_API_TOKEN=your-api-token

# =============================================================================
# GITHUB INTEGRATION
# =============================================================================
# Personal access token with repo scope
# Create at: https://github.com/settings/tokens
GITHUB_TOKEN=ghp_your-token

# Organization to scan
GITHUB_ORG=your-org

# =============================================================================
# GOOGLE INTEGRATION (for Google Docs enrichment)
# =============================================================================
# Path to OAuth credentials JSON
GOOGLE_CREDENTIALS_PATH=.secrets/credentials.json

# Path to token storage
GOOGLE_TOKEN_PATH=.secrets/token.json

# =============================================================================
# CONFLUENCE INTEGRATION
# =============================================================================
CONFLUENCE_URL=https://your-company.atlassian.net/wiki
CONFLUENCE_EMAIL=your.email@example.com
CONFLUENCE_API_TOKEN=your-api-token

# =============================================================================
# LLM PROVIDERS (for embeddings, entity extraction, AI features)
# Configure one or more providers - the system will use the first available
# =============================================================================

# --- OpenAI ---
# Create at: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-key
OPENAI_MODEL=gpt-4o                    # or gpt-4-turbo, gpt-3.5-turbo
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# --- Anthropic (Claude) ---
# Create at: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key
ANTHROPIC_MODEL=claude-sonnet-4-20250514       # or claude-opus-4-20250514, claude-3-haiku

# --- Google (Gemini) ---
# Create at: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=your-gemini-key
GEMINI_MODEL=gemini-2.0-flash          # or gemini-1.5-pro, gemini-1.5-flash

# --- Mistral ---
# Create at: https://console.mistral.ai/api-keys
MISTRAL_API_KEY=your-mistral-key
MISTRAL_MODEL=mistral-large-latest     # or mistral-medium, mistral-small, open-mistral-7b
MISTRAL_EMBEDDING_MODEL=mistral-embed

# --- Ollama (Local) ---
# No API key needed - just run Ollama locally
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3                    # or mistral, codellama, phi3

# --- Azure OpenAI ---
# For enterprise deployments
AZURE_OPENAI_API_KEY=your-azure-key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_DEPLOYMENT=your-deployment-name
AZURE_OPENAI_API_VERSION=2024-02-01

# --- AWS Bedrock ---
# Uses AWS credentials from environment or ~/.aws/credentials
AWS_REGION=us-east-1
BEDROCK_MODEL_ID=anthropic.claude-3-sonnet-20240229-v1:0

# =============================================================================
# LLM SELECTION
# =============================================================================
# Which provider to use by default (openai, anthropic, gemini, mistral, ollama, azure, bedrock)
LLM_PROVIDER=anthropic

# Fallback order if primary fails (comma-separated)
LLM_FALLBACK_ORDER=openai,gemini,ollama
